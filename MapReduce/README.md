# MapReduce Go Implementation

## Project Overview

This project is an implementation of the MapReduce programming model in Go. It provides a framework for processing large datasets with a distributed algorithm, using multiple nodes to perform map and reduce operations in parallel. The primary goal is to enable efficient data processing over large clusters, maximizing throughput and fault tolerance.

## Functionality

The MapReduce implementation includes several key components:

- **Master:** Coordinates the tasks among workers, handles task scheduling, and manages resource allocation.
- **Workers:** Execute the map and reduce functions assigned by the master.
- **RPC Calls:** Facilitate communication between the master and workers to distribute tasks and gather results.
- **Map Function:** Processes input data into intermediate key-value pairs.
- **Reduce Function:** Aggregates intermediate key-value pairs to produce final output.

## How It Works

### Initialization
The process begins with the master node taking input files and dividing them into smaller chunks, which are then assigned to worker nodes.

### Map Phase
Workers execute the map function on the assigned data chunks, processing each record into intermediate key-value pairs. The results are stored locally.

### Shuffling
Intermediate key-value pairs are redistributed based on the key, grouping all pairs of the same key to the same reduce worker. This shuffling ensures that all data belonging to a single key is located in one place.

### Reduce Phase
Reduce workers process each group of intermediate data, combining the values with the same key to form a single output value.

### Output
The final output values are written back to the storage system, completing the MapReduce operation.

## Running the Project

To execute the MapReduce framework:

1. Start the master node with the configuration specifying the number of workers and the dataset.
2. Launch worker nodes.
3. Submit jobs via the master nodeâ€™s API.

The system is designed to handle failures and can restart tasks in case of worker failures.

## Conclusion

This MapReduce implementation showcases the power of distributed computing in handling big data analytics. It leverages Go's concurrency features and efficient communication protocols to ensure robust and scalable data processing.
